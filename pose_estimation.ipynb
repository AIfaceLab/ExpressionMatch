{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, dlib, re, pyrender, trimesh\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadObj(file):\n",
    "    obj = {}\n",
    "    obj['v'],obj['vn'],obj['vt'],obj['f'] = [],[],[],[]\n",
    "    f = open(file, \"r\")\n",
    "    lines = f.readlines()\n",
    "    delimiters = \" \", \"//\", \"\\\\\",\"/\",\"\\\\\"\n",
    "    regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "    for item in lines:\n",
    "        data = re.split(regexPattern, item)\n",
    "        if 'v' == data[0]:\n",
    "            obj['v'].append(np.array(data[1:]).astype('float'))\n",
    "        elif 'vt' == data[0]:\n",
    "            obj['vt'].append(np.array(data[1:]).astype('float'))\n",
    "        elif 'vn' == data[0]:\n",
    "            obj['vn'].append(np.array(data[1:]).astype('float'))\n",
    "        elif 'f' == data[0]:\n",
    "            obj['f'].append(np.array(data[1:]).astype('int32'))\n",
    "    \n",
    "    hasVN,hasVT = False,False\n",
    "    if len(obj['v']):\n",
    "        obj['v'] = np.vstack(obj['v'])\n",
    "    if len(obj['vn']):\n",
    "        hasVN = True\n",
    "        obj['vn'] = np.vstack(obj['vn'])\n",
    "    if len(obj['vt']):\n",
    "        hasVT = True\n",
    "        obj['vt'] = np.vstack(obj['vt'])\n",
    "    if len(obj['f']):\n",
    "        obj['f'] = np.vstack(obj['f'])\n",
    "    \n",
    "    f = np.ones((9,obj['f'].shape[0]))\n",
    "    if  hasVN and hasVT:\n",
    "        f = obj['f'][:,[0,3,6,2,5,8,1,4,7]].T\n",
    "    elif hasVN and obj['f'].shape[1]==6:\n",
    "        f[:6] = obj['f'][:,[0,2,4,1,3,5]].T\n",
    "    elif hasVT and obj['f'].shape[1]==6:\n",
    "        f[[0,1,2,6,7,8]] = obj['f'][:,[0,2,4,1,3,5]].T\n",
    "    else:\n",
    "        f[[0,1,2]] = obj['f'].T\n",
    "    obj['f'] = f.astype('uint32')-1\n",
    "    return obj\n",
    "\n",
    "\n",
    "def rect_to_bb(rect):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "\n",
    "    # return a tuple of (x, y, w, h)\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def landmark_detect(gray):\n",
    "    rects = detector(gray, 1)\n",
    "    if len(rects)==0:\n",
    "        print('Couldn\\'t detect faces on the image.')\n",
    "        return\n",
    "        \n",
    "    rect = rects[0]\n",
    "    shape = predictor(gray, rect)\n",
    "    lm = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "    return lm\n",
    "\n",
    "def angle2matrix(pose):\n",
    "    ''' compute Rotation Matrix from three Euler angles\n",
    "    '''\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(pose[0]), -np.sin(pose[0])],\n",
    "                    [0, np.sin(pose[0]), np.cos(pose[0])]\n",
    "                    ])\n",
    "\n",
    "    R_y = np.array([[np.cos(pose[1]), 0, np.sin(pose[1])],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(pose[1]), 0, np.cos(pose[1])]\n",
    "                    ])\n",
    "\n",
    "    R_z = np.array([[np.cos(pose[2]), -np.sin(pose[2]), 0],\n",
    "                    [np.sin(pose[2]), np.cos(pose[2]), 0],\n",
    "                    [0, 0, 1]\n",
    "                    ])\n",
    "    R = np.dot(R_z, np.dot(R_y, R_x))\n",
    "    return R\n",
    "\n",
    "\n",
    "def isRotationMatrix(R):\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "\n",
    "def matrix2angle(R):\n",
    "    #assert (isRotationMatrix(R))\n",
    "\n",
    "    sy = np.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = np.arctan2(R[2, 1], R[2, 2])\n",
    "        y = np.arctan2(-R[2, 0], sy)\n",
    "        z = np.arctan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = np.arctan2(-R[1, 2], R[1, 1])\n",
    "        y = np.arctan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def render(mesh,cam,model=np.eye(4),f=[750,750],resolution=[512,512]):\n",
    "    # f [fx,fy]\n",
    "    fx, fy = f[0], f[1]\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
    "    fovY = 2*np.arctan(resolution[0]/2/fy)\n",
    "    # compose scene\n",
    "    scene = pyrender.Scene(ambient_light=[1.0, 1.0, 1.0], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.PerspectiveCamera( yfov=fovY)\n",
    "    light = pyrender.SpotLight(color=[1.0, 1.0, 1.0], intensity=3,innerConeAngle=0.05, outerConeAngle=0.5)\n",
    "#     light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=1.0)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  cam)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    return color,depth\n",
    "\n",
    "\n",
    "\n",
    "def save_to_pts(lm,file):\n",
    "    f = open(file,'w')\n",
    "    print('version: 1\\nn_points:  68\\n{',file=f)\n",
    "    for i in range(68):\n",
    "        print('%d %d'%(lm[i,0],lm[i,1]),file=f)\n",
    "    print('}',file=f)\n",
    "    f.close()\n",
    "    \n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (np.round(shape.part(i).x), np.round(shape.part(i).y))\n",
    "\n",
    "    return coords\n",
    "\n",
    "def ortho(frustum):\n",
    "    left,right,bottom,top = frustum[:]\n",
    "    projection = np.eye(4)\n",
    "    projection[0,0], projection[1,1],projection[2,2] = 2/(right - left), 2/(top - bottom), -1\n",
    "    projection[0,3],projection[1,3] = -(right + left) / (right - left),  -(top + bottom) / (top - bottom)\n",
    "    return projection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_predictor = '../shape_predictor_68_face_landmarks_dlib.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render2(mesh,cam=np.eye(4),model=np.eye(4),scale=[1,1],resolution=[720,1280]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
    "\n",
    "    scene = pyrender.Scene(ambient_light=[1.0, 1.0, 1.0], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.OrthographicCamera(xmag=1, ymag=resolution[0]/2/scale[1], znear=1e-3, zfar=10000.0)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, _ = r.render(scene)\n",
    "    \n",
    "    width = int(round(resolution[1]*scale[0]/scale[1]))\n",
    "    img = cv2.resize(color,(width,resolution[0]))\n",
    "    pad = (width - resolution[1])//2\n",
    "    right_pad = resolution[1] - width - abs(pad)\n",
    "    if pad > 0:\n",
    "        img = img[:,pad:pad+resolution[1]]\n",
    "    elif pad < 0:\n",
    "        img = np.pad(img, ((0,0),(abs(pad),right_pad),(0,0)), 'edge')\n",
    "    \n",
    "    return img,_\n",
    "\n",
    "def solveCamera(model_points,image_points):\n",
    "    # model_points, image_points N*M\n",
    "    A,b = np.zeros((2*model_points.shape[0],8)),np.zeros((2*model_points.shape[0],1))\n",
    "    ind = 0\n",
    "    for model_point, image_point in zip(model_points,image_points):\n",
    "        A[2*ind,:3],A[2*ind+1,4:7] = model_point[:3],model_point[:3]\n",
    "        A[2*ind,3],A[2*ind+1,7] = 1,1\n",
    "        b[2*ind:2*ind+2] = image_point.reshape((-1,1))\n",
    "        ind += 1\n",
    "    affine,_,_,_ = np.linalg.lstsq(A,b,rcond=None)\n",
    "    affine = affine.reshape((2,4))\n",
    "    \n",
    "    norms = np.linalg.norm(affine[:,:3],axis=1)\n",
    "    scale = norms\n",
    "    R = affine[:,:3]/norms.reshape((-1,1))\n",
    "    R1,R2 = R[0],R[1]\n",
    "    R3 = np.cross(R1,R2)\n",
    "    R3 /= np.linalg.norm(R3)\n",
    "    R = np.vstack((R1,R2,R3))\n",
    "\n",
    "    U,S,V = np.linalg.svd(R)\n",
    "    R_ortho = np.dot(U, V)\n",
    "    if np.linalg.det(R_ortho) < 0:\n",
    "        U[2,0] = -U[2,0]\n",
    "        R_ortho = np.dot(U, V)\n",
    "    t1,t2 = affine[0,3],affine[1,3]\n",
    "\n",
    "    MV = np.zeros((4,4))\n",
    "    MV[:3,:3] = R_ortho[:3]\n",
    "    MV[:2,3]  = (affine[:2,3] - np.array(img_size)/2)/scale\n",
    "    MV[3,3],MV[2,3] = 1, -200\n",
    "    \n",
    "    t1,t2 = affine[0,3]/scale[0],affine[1,3]/scale[1]\n",
    "    view_model = np.eye(4)\n",
    "    view_model[:3,:3] = R_ortho[:3]\n",
    "    view_model[:2,3]  = np.array([t1,t2])\n",
    "    frustum = np.array([0.0,img_size[0]/scale[0],0.0,img_size[1]/scale[1]])\n",
    "    ortho_projection = ortho(frustum)\n",
    "    mvp = np.dot(ortho_projection, view_model)\n",
    "    mvp[2,3] = -2\n",
    "    viewport = np.array([0, img_size[1], img_size[0], -img_size[1]]) # flips y, origin top-left, like in OpenCV\n",
    "    viewport_mat = np.array( [[viewport[2] / 2.0, 0.0, 0.0, viewport[2] / 2.0 + viewport[0]], \\\n",
    "                              [0.0,               viewport[3] / 2.0, 0.0, viewport[3] / 2.0 + viewport[1]], \\\n",
    "                              [0.0,               0.0,               1.0, 0.0], \\\n",
    "                              [0.0,               0.0,               0.0, 1.0]]) \n",
    "    full_projection = np.dot(viewport_mat, mvp)\n",
    "\n",
    "    return MV, affine, scale, full_projection\n",
    "\n",
    "def findNearestCooresponding(image_points,model_points,affine):\n",
    "    points = np.hstack((model_points,np.ones((model_points.shape[0],1))))\n",
    "    reProjection = np.dot(affine,points.T).T\n",
    "    model_ids = []\n",
    "    for item in image_points:\n",
    "        dis = np.sum(np.abs(reProjection - item.reshape((1,-1))),axis=1)\n",
    "        model_ids.append(np.argmin(dis))\n",
    "    return model_points[model_ids],model_ids\n",
    "\n",
    "def visLM(model_points, image_points, im,affine, homogeneous=False):\n",
    "    if homogeneous:\n",
    "        points = np.hstack((model_points,np.ones((model_points.shape[0],1))))\n",
    "    else:\n",
    "        points = model_points\n",
    "    points = np.dot(affine,points.T).T\n",
    "    for p in points:\n",
    "        cv2.circle(im, (int(p[0]), int(im.shape[0] - p[1])), 3, (0,255,0), -1)  \n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(im.shape[0] - p[1])), 3, (0,0,255), -1)  \n",
    "    return im\n",
    "\n",
    "def calReprojecErr(affine,point,lm):\n",
    "    point_img = np.dot(affine[:2,:3],point.T)+affine[:2,[3]]\n",
    "    return np.mean(np.abs(lm-point_img.T))                 \n",
    "    \n",
    "def buildEdgeTopology(mesh):\n",
    "    edges = []\n",
    "    for item in mesh.faces:\n",
    "        edges.append([item[0],item[1]])\n",
    "        edges.append([item[1],item[2]])\n",
    "        edges.append([item[2],item[0]])\n",
    "    return np.vstack(edges)\n",
    "\n",
    "def isFront(mesh,point_id):\n",
    "    z = mesh.vertices[:,2][point_id]\n",
    "    mask = z[:,0]>z[:,1]\n",
    "    front_id = np.unique(np.hstack((point_id[mask,0],point_id[~mask,1])))\n",
    "    return front_id\n",
    "\n",
    "def pointCloudClustering(vertices,thread):\n",
    "    isTravel = np.zeros(vertices.shape[0]).astype('bool')\n",
    "    while np.sum(isTravel) < vertices.shape[0]:\n",
    "        sample = np.where(isTravel)[0]\n",
    "        point = vertices[sample]\n",
    "        dis = np.sum(np.abs(vertices - point.reshape((1,-1))),axis=0)/3\n",
    "        ind = np.where(dis<thread)\n",
    "#         if isTravel[ind]\n",
    "    \n",
    "def findOcclusionEdge(mesh,MV,affine, contourLM, edge):\n",
    "    normal = np.dot(MV[:3,:3],mesh.vertex_normals.T).T\n",
    "    isBoundaries = normal[:,2][edge]>0\n",
    "    isBoundaries = isBoundaries[:,0]!=isBoundaries[:,1]\n",
    "    isBoundaries = np.where(isBoundaries)\n",
    "    point_id = []\n",
    "    for item in isBoundaries:\n",
    "        point_id.append(edge[item])\n",
    "    point_id = np.hstack(point_id)\n",
    "    \n",
    "    # Compute vertices that lye on occluding boundaries:\n",
    "    point_id = isFront(mesh,point_id)\n",
    "    points = mesh.vertices[point_id]\n",
    "    \n",
    "    # Project 3D boundaries to 2D\n",
    "    points = np.hstack((points,np.ones((points.shape[0],1))))\n",
    "    points_2D = np.dot(affine,points.T).T\n",
    "    \n",
    "    # Filter points far away\n",
    "    ids,ids_img = [],[]\n",
    "    threadHood = np.sum(np.abs(contourLM[0]-contourLM[-1]))/25\n",
    "    for i,item in enumerate(points_2D):\n",
    "        if  not contourMask[point_id[i]]:\n",
    "            continue\n",
    "        dis = np.sum(np.abs(contourLM-item.reshape((1,-1))),axis=1)\n",
    "        minimal_id = np.argmin(dis)\n",
    "        if dis[minimal_id] < threadHood:\n",
    "            ids.append(i)\n",
    "            ids_img.append(minimal_id)\n",
    "    point_id = point_id[ids]\n",
    "    return mesh.vertices[point_id],contourLM[ids_img], point_id\n",
    "\n",
    "def fitOccludingContour(angle,MV,affine,lm,image_ids,edge):\n",
    "    if angle[1]>= 0:\n",
    "        contour = lm[image_ids[1]]\n",
    "    else:\n",
    "        contour = lm[image_ids[0]]\n",
    "        \n",
    "    return findOcclusionEdge(mesh,MV,affine,contour,edge)\n",
    "\n",
    "def optimizeExp(obj_base,affine,w_exp,lm,ids,num_coeffs_to_fit=10,lamb=10.0):\n",
    "    #  affine*(v_base+ w_base*coef) = lm\n",
    "    # v_base n*3, w_base n*useBasis, coef useBasis*1, affine 3*4\n",
    "\n",
    "    lm_base, v_base = lm[ids['image_exp_ids']], obj_base.reshape((-1,3))[ids['model_exp_ids']]#\n",
    "    w_base = w_exp.reshape((-1,3,w_exp.shape[-1]))[ids['model_exp_ids']][...,:num_coeffs_to_fit].reshape((-1,num_coeffs_to_fit))\n",
    "    \n",
    "#     print(calReprojecErr(affine,v_base,lm_base))\n",
    "    \n",
    "    num_landmarks = v_base.shape[0]\n",
    "    y,v_bar = np.ones(3*num_landmarks),np.ones(4*num_landmarks)\n",
    "    V_hat_h = np.zeros((4 * num_landmarks, num_coeffs_to_fit))\n",
    "    P = np.zeros((3 * num_landmarks, 4 * num_landmarks))\n",
    "    for i in range(num_landmarks):\n",
    "        V_hat_h[i*4:i*4+3] = w_base[i*3:i*3+3]\n",
    "        P[i*3:i*3+3,i*4:i*4+4] = affine\n",
    "        y[i*3:i*3+2] = lm_base[i]\n",
    "        v_bar[4*i:4*i+3] = v_base[i]\n",
    "        \n",
    "    sigma_squared_2D = 3\n",
    "    Omega = np.eye(3 * num_landmarks)/sigma_squared_2D\n",
    "    \n",
    "    A = np.dot(P, V_hat_h)\n",
    "    b = np.dot(P, v_bar) - y\n",
    "    AtOmegaAReg = np.dot(np.dot(A.T,Omega), A) + lamb * np.eye(num_coeffs_to_fit)\n",
    "    rhs = - np.dot(np.dot(A.T, Omega), b)\n",
    "    \n",
    "    \n",
    "    # solve with qr\n",
    "    Q, R = np.linalg.qr(AtOmegaAReg)\n",
    "    y = np.dot(Q.T, rhs)\n",
    "    param = np.linalg.solve(R, y).reshape((-1,1))\n",
    "    obj_with_exp = obj_base + np.dot(w_exp[...,:num_coeffs_to_fit],param)\n",
    "#     print(calReprojecErr(affine,obj_with_exp.reshape((-1,3))[ids['model_exp_ids']],lm_base))\n",
    "    return obj_with_exp,param\n",
    "\n",
    "def optimizePose(mesh,lm,ids,steps=10): \n",
    "    \n",
    "    image_5point_ids,model_5point_ids,model_ids,image_ids = ids['image_5point_ids'],ids['model_5point_ids'],ids['model_ids'],ids['image_ids']\n",
    "    model_points = mesh.vertices[model_5point_ids].astype('float32')\n",
    "    image_points = lm[image_5point_ids].astype('float32')\n",
    "    MV,affine,scale,full_projection = solveCamera(model_points,image_points)\n",
    "\n",
    "    for iter in range(steps):\n",
    "\n",
    "        threadHood = 7.5/180*np.pi\n",
    "        angle = matrix2angle(MV[:3,:3])\n",
    "\n",
    "        model_points = mesh.vertices[model_5point_ids].astype('float32')\n",
    "        image_points = lm[image_5point_ids].astype('float32')\n",
    "        model_ids_new = np.array(model_5point_ids)\n",
    "\n",
    "        if  angle[1] < threadHood:\n",
    "            image_points_add, model_points_add = lm[image_ids[1]],mesh.vertices[model_ids[1]]\n",
    "            model_points_add, model_ids_add = findNearestCooresponding(image_points_add, model_points_add,affine)\n",
    "            \n",
    "            image_points = np.vstack((image_points,image_points_add))\n",
    "            model_points = np.vstack((model_points,model_points_add))\n",
    "            model_ids_new = np.hstack((model_ids_new,model_ids[1][model_ids_add]))\n",
    "\n",
    "        if angle[1] > -threadHood:\n",
    "            image_points_add, model_points_add = lm[image_ids[0]],mesh.vertices[model_ids[0]]\n",
    "            model_points_add, model_ids_add = findNearestCooresponding(image_points_add, model_points_add,affine)\n",
    "\n",
    "            image_points = np.vstack((image_points,image_points_add))\n",
    "            model_points = np.vstack((model_points,model_points_add))\n",
    "            model_ids_new = np.hstack((model_ids_new,model_ids[0][model_ids_add]))\n",
    "\n",
    "#         MV,affine,scale,full_projection = solveCamera(model_points,image_points)\n",
    "        contour_3D,contour_2D,model_ids_add = fitOccludingContour(angle,MV,affine,lm,image_ids,edge)\n",
    "        image_points = np.vstack((image_points,contour_2D))\n",
    "        model_points = np.vstack((model_points,contour_3D))\n",
    "        model_ids_new = np.hstack((model_ids_new,model_ids_add))\n",
    "       \n",
    "        MV,affine,scale,full_projection = solveCamera(model_points,image_points)\n",
    "        affine2 = np.vstack((affine,np.array([0,0,0,1])))\n",
    "        vertice,param = optimizeExp(obj_base,affine2,models['w_exp'],lm,ids)\n",
    "    \n",
    "    mesh.vertices = vertice.reshape((-1,3))\n",
    "    \n",
    "    return MV,affine,scale,image_points,model_points,full_projection,model_ids_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to load materials from: image_0010.out.mtl\n",
      "specified material (FaceTexture)  not loaded!\n"
     ]
    }
   ],
   "source": [
    "imageFolder = 'video.mp4'\n",
    "vc = cv2.VideoCapture(imageFolder)\n",
    "frameCount,maxFrame,sampling = 0,100,1\n",
    "success, im = vc.read()\n",
    "mesh = trimesh.load('obama.obj',process=False)\n",
    "contourMask = np.load('contourMask.npy')\n",
    "edge = buildEdgeTopology(mesh)\n",
    "\n",
    "image_mouse_ids = np.array(range(49,69))-1\n",
    "model_mouse_ids = np.array([5522,6026,7355,8181,9007,10329,10857,9730,8670,8199,7726,6898,6291,7364,8190,9016,10088,8663,8191,7719])\n",
    "image_5point_ids = np.hstack((np.array([30,8]),np.array(range(36,48))))\n",
    "model_5point_ids = np.hstack((np.array([8156,47846]),np.array([2602,4147,4921,6088,4931,4157,10390,11031,11932,13481,12072,11298])))\n",
    "image_5point_ids,model_5point_ids = np.hstack((image_5point_ids,image_mouse_ids)),np.hstack((model_5point_ids,model_mouse_ids))\n",
    "\n",
    "\n",
    "model_ids = np.array([[22057,22209,21582,21350,42838,44845,46470,47262], \\\n",
    "                      [48432, 49307,50856,52755,33087,32933,32141,32249]])# right left\n",
    "\n",
    "image_ids = np.array([[0,1,2,3,4,5,6,7],[9,10,11,12,13,14,15,16]])\n",
    "image_exp_ids = image_mouse_ids #np.array(range(61,69))-1\n",
    "model_exp_ids = model_mouse_ids #np.array([6291,7364,8190,9016,10088,8663,8191,7719 ])\n",
    "# image_exp_ids = np.hstack((np.array(range(37,49)),np.array(range(61,69))))-1\n",
    "# model_exp_ids = np.array([2602,4147,4921,6088,4931,4157,10390,11031,11932,13481,12072,11298,6291,7364,8190,9016,10088,8663,8191,7719 ])\n",
    "ids = {'image_5point_ids':image_5point_ids,'model_5point_ids':model_5point_ids,'model_ids':model_ids,'image_ids':image_ids, \\\n",
    "       'image_exp_ids':image_exp_ids, 'model_exp_ids':model_exp_ids}\n",
    "  \n",
    "# face model\n",
    "filename = './Model_Shape.mat'\n",
    "models = loadmat(filename)\n",
    "\n",
    "sigma_exp,sigma = models['sigma_exp'],models['sigma']\n",
    "models['w'] = models['w']*np.repeat(sigma,models['w'].shape[0],axis=1).T\n",
    "models['w_exp'] = models['w_exp']*np.repeat(sigma_exp,models['w_exp'].shape[0],axis=1).T\n",
    "shape_coef = np.loadtxt('./00000.jpg.coeffs_pca_shape.txt').reshape((-1,1))\n",
    "#exp_coef = np.loadtxt('E:/mesh2face/pose_estimation/eos-expression-aware-proxy/build/examples/data/res/00000.jpg.coeffs_expression.txt').reshape((-1,1))\n",
    "obj_base = models['mu_shape'] + models['mu_exp'] + np.dot(models['w'],shape_coef) #+ np.dot(models['w_exp'],exp_coef)\n",
    "mesh.vertices = obj_base.reshape((-1,3))\n",
    "\n",
    "lms = np.load('obama_lm.npy')\n",
    "while success and frameCount < maxFrame:\n",
    "    \n",
    "    img_size = (im.shape[1], im.shape[0])\n",
    "    lm = lms[frameCount,0]\n",
    "    lm[:,1] = img_size[1] - lm[:,1]\n",
    "    \n",
    "    mesh.vertices = obj_base.reshape((-1,3))\n",
    "    MV,affine,scale,image_points,model_points,full_projection,model_ids = optimizePose(mesh,lm,ids,steps=3)\n",
    "\n",
    "    \n",
    "    renderedImg, depth = render2(mesh,model=MV,scale=scale)\n",
    "    mask = np.sum(renderedImg,axis=2)>0\n",
    "    im[mask] = renderedImg[mask]*0.5 + im[mask]*0.5\n",
    "\n",
    "    im = visLM(mesh.vertices[model_ids],image_points,im, affine,homogeneous=True)\n",
    "#     im = visLM(mesh.vertices[model_exp_ids],lm[image_exp_ids],im, affine,homogeneous=True)\n",
    "    \n",
    "#     plt.imshow(img[...,::-1])\n",
    "#     p1 = ( int(image_points[-3][0]), int(image_points[-3][1]))\n",
    "#     p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "#     cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    shape, scale = im.shape, 1\n",
    "    cv2.imshow(\"Output\", cv2.resize(im,(shape[1]//scale,shape[0]//scale)))\n",
    "    if  cv2.waitKey(33) & 0xFF == ord('q'):#\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "#     np.savetxt('optimize_v1/%03d.txt'%frameCount,model_points)\n",
    "    cv2.imwrite('optimize_v3/%03d.jpg'%frameCount,im)\n",
    "    frameCount += 1\n",
    "    if maxFrame -1 >0:\n",
    "        vc.set(cv2.CAP_PROP_POS_FRAMES, frameCount*sampling)\n",
    "    success, im = vc.read()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to load materials from: image_0010.out.mtl\n",
      "specified material (FaceTexture)  not loaded!\n"
     ]
    }
   ],
   "source": [
    "imageFolder = 'video.mp4'\n",
    "vc = cv2.VideoCapture(imageFolder)\n",
    "frameCount,maxFrame,sampling = 0,100,1\n",
    "success, im = vc.read()\n",
    "mesh = trimesh.load('obama.obj',process=False)\n",
    "contourMask = np.load('contourMask.npy')\n",
    "edge = buildEdgeTopology(mesh)\n",
    "\n",
    "image_mouse_ids = np.array(range(49,69))-1\n",
    "model_mouse_ids = np.array([5522,6026,7355,8181,9007,10329,10857,9730,8670,8199,7726,6898,6291,7364,8190,9016,10088,8663,8191,7719])\n",
    "image_5point_ids = np.hstack((np.array([30,8]),np.array(range(36,48))))\n",
    "model_5point_ids = np.hstack((np.array([8156,47846]),np.array([2602,4147,4921,6088,4931,4157,10390,11031,11932,13481,12072,11298])))\n",
    "image_5point_ids,model_5point_ids = np.hstack((image_5point_ids,image_mouse_ids)),np.hstack((model_5point_ids,model_mouse_ids))\n",
    "\n",
    "\n",
    "model_ids = np.array([[22057,22209,21582,21350,42838,44845,46470,47262], \\\n",
    "                      [48432, 49307,50856,52755,33087,32933,32141,32249]])# right left\n",
    "\n",
    "image_ids = np.array([[0,1,2,3,4,5,6,7],[9,10,11,12,13,14,15,16]])\n",
    "image_exp_ids = image_mouse_ids #np.array(range(61,69))-1\n",
    "model_exp_ids = model_mouse_ids #np.array([6291,7364,8190,9016,10088,8663,8191,7719 ])\n",
    "# image_exp_ids = np.hstack((np.array(range(37,49)),np.array(range(61,69))))-1\n",
    "# model_exp_ids = np.array([2602,4147,4921,6088,4931,4157,10390,11031,11932,13481,12072,11298,6291,7364,8190,9016,10088,8663,8191,7719 ])\n",
    "ids = {'image_5point_ids':image_5point_ids,'model_5point_ids':model_5point_ids,'model_ids':model_ids,'image_ids':image_ids, \\\n",
    "       'image_exp_ids':image_exp_ids, 'model_exp_ids':model_exp_ids}\n",
    "  \n",
    "# face model\n",
    "filename = './Model_Shape.mat'\n",
    "models = loadmat(filename)\n",
    "\n",
    "sigma_exp,sigma = models['sigma_exp'],models['sigma']\n",
    "models['w'] = models['w']*np.repeat(sigma,models['w'].shape[0],axis=1).T\n",
    "models['w_exp'] = models['w_exp']*np.repeat(sigma_exp,models['w_exp'].shape[0],axis=1).T\n",
    "shape_coef = np.loadtxt('E:/mesh2face/pose_estimation/eos-expression-aware-proxy/build/examples/data/res/00000.jpg.coeffs_pca_shape.txt').reshape((-1,1))\n",
    "#exp_coef = np.loadtxt('E:/mesh2face/pose_estimation/eos-expression-aware-proxy/build/examples/data/res/00000.jpg.coeffs_expression.txt').reshape((-1,1))\n",
    "obj_base = models['mu_shape'] + models['mu_exp'] + np.dot(models['w'],shape_coef) #+ np.dot(models['w_exp'],exp_coef)\n",
    "mesh.vertices = obj_base.reshape((-1,3))\n",
    "\n",
    "while success and frameCount < maxFrame:\n",
    "    \n",
    "    img_size = (im.shape[1], im.shape[0])\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    lm = landmark_detect(gray)\n",
    "    lm[:,1] = img_size[1] - lm[:,1]\n",
    "    \n",
    "    mesh.vertices = obj_base.reshape((-1,3))\n",
    "    MV,affine,scale,image_points,model_points,full_projection,model_ids = optimizePose(mesh,lm,ids,steps=3)\n",
    "\n",
    "    \n",
    "    renderedImg, depth = render2(mesh,model=MV,scale=scale)\n",
    "    mask = np.sum(renderedImg,axis=2)>0\n",
    "    im[mask] = renderedImg[mask]*0.5 + im[mask]*0.5\n",
    "\n",
    "#     im = visLM(mesh.vertices[model_ids],image_points,im, affine,homogeneous=True)\n",
    "#     im = visLM(mesh.vertices[model_exp_ids],lm[image_exp_ids],im, affine,homogeneous=True)\n",
    "    \n",
    "#     plt.imshow(img[...,::-1])\n",
    "#     p1 = ( int(image_points[-3][0]), int(image_points[-3][1]))\n",
    "#     p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "#     cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    shape, scale = im.shape, 1\n",
    "    cv2.imshow(\"Output\", cv2.resize(im,(shape[1]//scale,shape[0]//scale)))\n",
    "    if  cv2.waitKey(33) & 0xFF == ord('q'):#\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "#     np.savetxt('optimize_v1/%03d.txt'%frameCount,model_points)\n",
    "    cv2.imwrite('optimize_v2/%03d.jpg'%frameCount,im)\n",
    "    frameCount += 1\n",
    "    if maxFrame -1 >0:\n",
    "        vc.set(cv2.CAP_PROP_POS_FRAMES, frameCount*sampling)\n",
    "    success, im = vc.read()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# mesh.export('test.obj');\n",
    "# mesh.vertices = obj_base.reshape((-1,3))\n",
    "# mesh.export('test2.obj');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7f664e81cac7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# image feature points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlandmark_detect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mimage_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m39\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-63afbc142814>\u001b[0m in \u001b[0;36mlandmark_detect\u001b[1;34m(gray)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "barycentricsModel = np.load('barycentricsModels.npy',allow_pickle=True)[()]\n",
    "barycentrics, indTri = barycentricsModel['barycentrics'],barycentricsModel['indTri']\n",
    "barycentrics = np.repeat(barycentrics[...,np.newaxis],3,-1)\n",
    "\n",
    "for ind in range(384000, 405000,1000):\n",
    "    im = cv2.imread('./test/%07d_input.png'%ind)\n",
    "    img_size = (im.shape[1], im.shape[0])\n",
    "\n",
    "    # image feature points\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    lm = landmark_detect(gray)\n",
    "    image_points = lm[[36,39,42,45,27,28,29,30,8]].astype('float32')\n",
    "\n",
    "    # 3d feature points\n",
    "    mesh = trimesh.load('./test/demo_%07d.obj'%ind,process=False)\n",
    "    vertices = mesh.vertices[mesh.faces[indTri.astype('int32')]]\n",
    "    model_points = np.sum(vertices * barycentrics,axis=1).astype('float32')\n",
    "\n",
    "\n",
    "    focal_length = img_size[0]*4\n",
    "    center = np.array(img_size)/2\n",
    "    camera_matrix = np.array([[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "\n",
    "\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    # retval, camera_matrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(model_points[np.newaxis], image_points[np.newaxis], img_size,camera_matrix,None,flags=cv2.CALIB_USE_INTRINSIC_GUESS)\n",
    "    # rvec, tvec = rvecs[0],tvecs[0]\n",
    "    _, rvec, tvec, _ = cv2.solvePnPRansac(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_UPNP )\n",
    "    r = Rotation.from_rotvec(rvec.reshape((-1))).as_dcm()\n",
    "    extrins = np.hstack([r,tvec])\n",
    "    extrins = np.vstack([extrins,np.array([0,0,0,1])])\n",
    "\n",
    "    # print(\"Camera Matrix :\\n {0}\".format(camera_matrix))\n",
    "    # print(\"Rotation Vector:\\n {0}\".format(rotation_vector))\n",
    "    # print(\"Translation Vector:\\n {0}\".format(translation_vector))\n",
    "\n",
    "    nose_end_point3D = model_points[-2] + np.array([(0.0, 0.0, 0.05)])\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(nose_end_point3D, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Display image\n",
    "    # cv2.imshow(\"Output\", im)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    MV = np.eye(4)\n",
    "    mv = extrins.copy()\n",
    "    mv[[0,2]] = -mv[[0,2]]\n",
    "    renderedImg, depth = render(mesh,MV,model=mv,f=[camera_matrix[0,0],camera_matrix[1,1]],resolution=img_size)\n",
    "    mask,renderedImg = depth[::-1,::-1]>0,renderedImg[::-1,::-1,::-1]\n",
    "    im[mask] = renderedImg[mask]*0.8 + im[mask]*0.2\n",
    "\n",
    "    point = np.dot(camera_matrix,np.dot(extrins[:3,:3],model_points.T)+extrins[:3,3].reshape((3,1)))\n",
    "    point = point[:2]/point[2]\n",
    "    for p in point.T:\n",
    "        cv2.circle(im, (int(p[0]), int(p[1])), 2, (0,255,0), -1)  \n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(p[1])), 2, (0,0,255), -1)  \n",
    "    p1 = ( int(image_points[-2][0]), int(image_points[-2][1]))\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "#     plt.imshow(im[...,::-1])\n",
    "    cv2.imwrite('render/%07d.jpg'%ind,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'E:/mesh2face/pose_estimation/optimize_v2/video.mp4'\n",
    "video_images = 'E:/mesh2face/pose_estimation/optimize_v2/'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(video, fourcc, 5, (1280,720))\n",
    "List = sorted(os.listdir(video_images))\n",
    " \n",
    "for item in List:\n",
    "    if not item.endswith('g'):\n",
    "        continue\n",
    "    img = cv2.imread(os.path.join(video_images,item))\n",
    "    out.write(img)\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
